// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser, LocalTokenGroup} from "@lezer/lr"
export const parser = LRParser.deserialize({
  version: 14,
  states: "#lO`QPOOPkOPOOOOQO'#Cd'#CdOOQO'#Cc'#CcOpQPO'#CbOOQO'#Ca'#CaOOQO'#Ch'#ChOuQPO'#C`QOQPOOP!QOQO'#C^POOO)C>`)C>`O!]QPO'#CfOOQO,58|,58|OOQO-E6f-E6fPOOO'#Cg'#CgP!bOQO,58xPOOO,58x,58xOOQO,59Q,59QPOOO-E6e-E6ePOOO1G.d1G.d",
  stateData: "!m~O_OS`OSPOSaPQ~OXQO]SPeVP~OaXO~OeZO~OXQO]SXeVP~Ob^Oc^Od`O~OfaO~Ob^Oc^OdcO~O",
  goto: "!T]PP^PadhlpPtw}RYPRWOTUOVTTOVTSOVTROVR[SQ_XRb_QVOR]V",
  nodeNames: "âš  LineComment BlockComment Input Items Item HeaderBlock Header Namespace Identifier Block",
  maxTerm: 22,
  skippedNodes: [0,1,2,11],
  repeatNodeCount: 2,
  tokenData: "$W~R^XY}YZ!Ypq}tu!_}!O#S!P!Q#q!c!}!_#R#S!_#T#o!_#o#p#|#q#r$R$g;'S!_;'S;=`!|<%lO!_~!SQ_~XY}pq}~!_O`~~!dWX~tu!_!Q![!_!c!}!_#R#S!_#T#o!_$g;'S!_;'S;=`!|<%lO!_~#PP;=`<%l!_~#VP}!O#Y~#_SP~OY#YZ;'S#Y;'S;=`#k<%lO#Y~#nP;=`<%l#Y~#tPz{#w~#|Oa~~$ROe~~$WOf~",
  tokenizers: [1, new LocalTokenGroup("j~RQYZXz{^~^Oc~~aP!P!Qd~iOd~~", 25, 18)],
  topRules: {"Input":[0,3]},
  tokenPrec: 0
})
